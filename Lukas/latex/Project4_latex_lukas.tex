\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{fourier}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\author{Johannes Scheller, Vincent Noculak, Lukas Powalla, Richard Asbah}
\title{Computational Physics - Project 4}

\lstset{language=C++,
	keywordstyle=\bfseries\color{blue},
	commentstyle=\itshape\color{red},
	stringstyle=\color{green},
	identifierstyle=\bfseries,
	frame=single}
\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\section*{Introduction}
In project 4 we are dealing with the Ising model in two dimensions without an external magnetic field. We are looking at a lattice of L times L particles, which have spinvalues $\pm 1$. In order to compute different interesting values, we want to use the metropolis algorithm.  With our computations, we want to calculate the Energy, the absolute value of the magnetisation, the heat capacity and susceptibility of the system as a function of time. We also want to compare our solutions with the theoretical closed solution. 
We are also looking at phase transitions of our system. In our case, it will be a second order phase transition. (which in a canonial ensemble means a divergence of the heat capacity)
This project may also show the link from statistical physics to macroscopic properties of a given physical system, which is a very interesting relation. 
\section{Theory}

\subsection{General properties of physical systems and their link to statistical physics}

\subsubsection{physical ensembles}
%Lukas changed this; newest version 08.11.15
Let us now look at a physical system and its surroundings. 
In principle, it is necessary to describe the relation of the physical system and its surroundings in order to determine the properties of the system.(sometimes this relations are related to physical boundary conditions) It is necessary to know whether we want to allow for instance particle/heat exchange or not. How we set up our system also defines us the thermodynamic potential, which can be used to describe the system.(e.g. Entropy, Helmholtz,Gibbs) All in all, we have the Microcanonical ensemble, the canonical ensemble, the Grandcanonical ensemble and the pressure canonical ensemble. (in this case an ensemble means a collection of mircoscopic systems, compare with the lecture notes Computational physics 2015 at University of Oslo by Morten Hjorth-Jensen page 417 )
In the following, we will always deal with the canonical ensemble. This  means that we don't allow particle exchange from the system with its surroundings, but we allow exchange of heat with the environment. 
Fixed variables are in this case the temperature, the total volume and the total particle number. The total energy of the canonical ensemble is not constant, because there can be heat exchange with the surroundings. The system, which does not allow heat exchange and does not allow particle exchange is called micro-canonical ensemble. (compare "Statistical Mechanics  An Intermediate Course; 2nd Edition; G. Morandi/F. Napoli/ E. Ercolessi; page 94ff") 
The probability distribution is given by the Boltzmann distribution.

\begin{align}
P_i (\beta) =\frac{ e^{- \beta E_i}}{Z}
\end{align} 
$\beta = 1/k_B T$ where T is the temperature, $k_B$ is the Boltzmann constant,$E_i$ is the energy of micro state i and Z is the partition function for the canonical ensemble is the sum over all the micro states M.

\begin{equation}
  Z=\sum_{i=1}^{M}e^{- \beta E_i}
\end{equation}
   

\subsubsection{General properties of canonical ensembles}\label{General properties of canonical ensembles}
%Lukas changed this; newest version 08.11.15
The canonical ensemble can be expressed by Helmholtz' free energy. The system strives to a minimum of Helmholtz' free energy, which is defined as follows:
\begin{equation}
F=-k_BTlnZ = <E>-TS \label{F}
\end{equation}
where the entropy S is given by
\begin{equation}
S=-k_BlnZ + k_B T \frac{\partial lnZ}{\partial T}\label{S}
\end{equation}
We can see that $F$ depends on the expectation value of the Energy and on $-TS$. 
Hence, the canonical ensemble pursuits towards an energy minimum and higher entropy. This can be interpreted as a "struggle between two important principles in physics"( lecture notes Computational physics 2015 at University of Oslo by Morten Hjorth-Jensen page 419 )

After running the system for long time the canonical ensemble is uniquely determined and does not depend on the arbitrary choices of the initial temperature.
The system uncertainty due the Energy fluctuations in the canonical ensemble gives the variance of the energy.\\
 
%from here on,  Richards actual part


\centerline{ from equation \ref{F}, \ref{S} and probability distribution $P_i$ }
\begin{align}
<E> = k_b T^2 \frac{\partial lnZ}{\partial T}=\sum_{i=1}^{M} E_iP_i(\beta)=\frac{1}{Z }\sum_{i=1}^{M}E_i e ^{ - \beta E_i}
\end{align}
The heat capacity is how much the energy change due to the change in the temperature. The heat capacity $C_V$ can be defined as

\begin{equation}
C_V =\frac{\partial E}{\partial T} 
\end{equation}

\begin{equation}
\frac{\partial}{\partial T}\frac{1}{Z} = \frac{\partial}{\partial T}\frac{1}{\sum_{i=1}^{M}e^{- \frac{1}{k_BT} E_i}} = -\frac{1}{k_B T^2 } \frac{\sum_{i=1}^{M} E_i e^{-E_i \frac{1}{k_BT}}}{\left(\sum_{i=1}^{M} e^{-E_i \frac{1}{k_BT}} \right)^2}=-\frac{1}{k_B T^2 } \frac{\sum_{i=1}^{M} E_i e^{-E_i \frac{1}{k_BT}}}{\left( Z\right)^2}
\end{equation}

\begin{equation}
\frac{\partial}{\partial T}\sum_{i=1}^{M}E_i e ^{ - \frac {1}{k_BT} E_i} = \frac{1}{k_BT^2}\sum_{i=1}^{M}E_i^2 e ^{ - \frac {1}{k_BT} E_i}
\end{equation}

\begin{align}
C_V &=\frac{\partial <E>}{\partial T} = \frac{\partial}{\partial T} \left( \frac{1}{Z }\sum_{i=1}^{M}E_i e ^{ - \frac {1}{k_BT} E_i}\right) = -\frac{1}{k_B T^2 } \frac{\sum_{i=1}^{M} E_i e^{-E_i \frac{1}{k_BT}}}{ Z^2}\sum_{i=1}^{M}E_i e ^{ - \frac {1}{k_BT} E_i} +\frac{1}{Z}\frac{1}{k_BT^2}\sum_{i=1}^{M}E_i^2 e ^{ - \frac {1}{k_BT} E_i} \\
 &= -\frac{1}{k_B T^2 } \left( \frac{\sum_{i=1}^{M} E_i e^{-E_i \frac{1}{k_BT}}}{ Z} \right)^2 +\frac{1}{Z}\frac{1}{k_BT^2}\sum_{i=1}^{M}E_i^2 e ^{ - \frac {1}{k_BT} E_i} = \frac{1}{k_B T^2 } \left( <E>^2 - <E^2> \right)
\end{align}
\subsubsection{Ferromagnetic order}
% not clearly understandeble (comment by Lukas )
A ferromagnet has a spontaneous magnetic moment even with the absence of an external magnetic field. Due the existence of a spontaneous moment the electron spin and magnetic moments must be arranged in a regular manner.
Ferromagnet all spin aligned, anti ferromagnet all spin align with neighbouring pointing in opposite directions, ferromagnet the opposing moments are unequal , etc.

\subsubsection{link from the Macroscopic values to statistical physics}
%Lukas newest upgrade 08.11.15
In chapter \ref{General properties of canonical ensembles}, we derived the expression of the heat capacity and of the magnetic susceptibility of a canonical ensemble. We didn't care about statistical properties. However, what strikes the eye is that in the expression of the heat capacity as well as in the expression of the magnetic susceptibility, we see that they both depend on the variance of the energy of the magnetisation. this means that they can be written as:
\begin{align}
C_v &= \frac{1}{k_B T^2}\cdot \mathrm{Var(E)}\\
\chi &= \frac{1}{k_B T} \cdot \mathrm{Var(M)}
\end{align}
The variance measures how far away a set of numbers is spread out. A huge variance means then that the values of the quantity fluctuate a lot around the expectation value.  Now, we have linked a statistical property to a thermodynamic and macroscopic such as heat capacity. 
\subsection{theoretical numerical solutions}

\subsubsection{Ising model}
Ising model is a mathematical model for ferromagnetism studies of phase transitions for magnetic system at given a temperature. The model consists the interaction between two neighbouring spins is related by the interaction energy 
\begin{equation}
  -Js_ks_l
\end{equation} 
where the sin s can be in two states +1 or -1,where  $s_k$ and $s_l$ are the nearest neighbors. Which give a low energy (-J) if the two spin aligned and high energy (j) for spin pointing in opposite direction. The total energy to a system with N number of spins and with the absence of magnetic field can be expressed as 
\begin{equation}
  E=-J\sum_{<kl>}^{N}s_ks_l
\end{equation}

  
  \subsubsection{Periodic boundary conditions} 
Periodic boundary conditions is used for approximating a large or infinite system by using smaller repeating system, we will impose PBCs on our spin lattice in x and y directions.

 s(L+1,y) = s(1,y)
 
 s(x,L+1) = s(X,1)  

\subsubsection{Metropolis algorithm}
%Richi... it's ur turn ;)
\subsubsection{critical temperature (Lars Onsager)}
% Richi, It's ur turn
\subsection{Closed solution for a 2 dimensional 2 x 2 lattice}

We want now to look at a 2 x 2 lattice and we want to calculate the partition function, the energy, magnetisation, heat capacity and susceptibility of the system  dependent of T. 
The partition function for a canonical ensemble with periodic boundary conditions can be computed  by:
\begin{align}
Z= \sum_{i=1}^{M} e^{- \beta E_i}
\end{align} 
Here, $\beta$ is $\frac{1}{k_b \cdot T}$, where $k_b$ is the Bolzmann constant. 
In this expression we sum over all microstates m. The Energy of the system in configuration i is then:
\begin{align}
E_i = - J \sum_{<kl>}^N s_k s_l 
\end{align} 

The sum over $<kl>$ means that we only sum over nearest neighbours. In our 2 x 2 case, we have for each "particle" two possible values $\pm 1$. This means that we have all in all $2^{2 \cdot 2} = 2^4=16$ micro states. We have to compute the Energy of the micro states in order to compute the partition function. 
We also want to introduce the magnetisation, which is simply the sum over all the spins of the system:
\begin{align}
M_i=\sum_{j=1}^N s_j
\end{align}
We want also to introduce the so called degeneracy, which counts the number of micro states for a given micro energy. We get the following table:
\begin{figure}[h]
\centering
\caption{Energy of the different micro states}
\label{table of microstates}
\begin{tabular}{c|c|c|c}
Number of spins up (+1) & Degeneracy &  Energy & Magnetization\\
\hline \hline
4 & 1 & $-8J$ & 4 \\
3 & 4 & 0 & 2 \\
2 & 4 & 0 & 0 \\
2 & 2 & $8J$ & 0 \\
1 & 4 & 0 & -2 \\
0 & 1 & $-8J$ & -4 
\end{tabular}
\end{figure}
We can now write the expression of the partition function as in equation \ref{Partition 2x2}. We used the Table \ref{table of microstates} to calculate the sum over the micro states. 
\begin{align}
Z&= \sum_{i=1}^{M} e^{- \beta E_i}= 12 \cdot e^{-\beta \cdot 0 } + 2 \cdot e^{-8J \beta } + 1 \cdot e^{8J \beta } + 1 \cdot e^{8J \beta } \\
&= 12+ 2 \cdot e^{-8J \beta } + 2 \cdot e^{8J \beta } \\
&= 12+ 4 \cdot \mathrm{cosh} \left( 8J \beta \right) \label{Partition 2x2}
\end{align} 
We can now calculate the expectation value of the energy. There are two possible ways of calculating it. the first way of calculating the expectation value of the energy can be seen in equation \ref{Energyexpectation way1}. 
\begin{align}
<E>&= - \frac{\partial ln(Z)}{\partial \beta} =-\frac{1}{Z} \cdot 32J  \cdot \mathrm{sinh}(8J \beta ) \\ \label{Energyexpectation way1}
&= -\frac{32 J \cdot \mathrm{sinh}((8J \beta )}{Z}\\
&=-\frac{8 \cdot J \cdot  \mathrm{sinh}(8J \beta ) }{3+\mathrm{cosh}(8J\beta)}
\end{align}
Alternatively, we can calculate the expectation value of the Energy by looking at the micro states:
\begin{align}
<E> =- \frac{1}{Z} \sum_{i=1}^{M} E_i e^{- \beta E_i}=-\frac{8 \cdot J \cdot  \mathrm{sinh}(8J \beta ) }{3+\mathrm{cosh}(8J\beta)}
\end{align}
Both expressions are equal. Next, we want to determine the expectation value of the magnetisation. We use the formula \ref{expectation magnetisation 2x2}. We can see that we get 0 for the expectation value of the magnetisation. 
\begin{align}
<M> &= \frac{1}{Z} \sum_{i}^M M_i \cdot e^{- \beta E_i }\\\label{expectation magnetisation 2x2}
&= \frac{1}{Z} \cdot \left( 4 \cdot 1 \cdot e^{-8J\beta}+ 2 \cdot 4+(-2) \cdot 4 + (-4) \cdot 1 \cdot e^{-8J \beta } \right)\\
&=0
\end{align}
However, we are interested in the expectation value of the absolute value of magnetisation, which is $<|M|>$. This expression can be determined as follows:
\begin{align}
<|M|> &= \frac{1}{Z} \sum_{i}^M |M_i| \cdot e^{- \beta E_i }\\\label{expectation absolute magnetisation 2x2}
&= \frac{1}{Z} \cdot \left( |4| \cdot 1 \cdot e^{-8J\beta}+ |2| \cdot 4+|(-2)| \cdot 4 + |(-4)| \cdot 1 \cdot e^{-8J \beta } \right)\\
&=\frac{1}{Z} \cdot \left( 8 \cdot e^{-8J\beta} +8 \right)\\
&= \frac{2 \cdot e^{-8J\beta}+2}{3+ \mathrm{cosh}(8J\beta)}
\end{align}
In order to describe how the temperature will change when thermal energy is added to the system, we want to look at a quantity called heap capacity. ($C_v$) The bigger this quantity is the less heats the system up by a given amount of thermal energy, which is added to the system.  
\begin{align}
C_v &= \frac{1}{k_b T^2} \left( \frac{1}{Z} \sum_{i=1}^{M} E_i^2 e^{- \beta E_i } - \left( \frac{1}{Z} \sum_{i=1}^{M} E_i e^{- \beta E_i }  \right)^2 \right)\\
&=\frac{1}{k_b T^2} \left( \frac{1}{Z} \left( 2 \cdot (8J)^2 \cdot e^{8J \beta}+2 \cdot (-8J)^2 \cdot e^{-8J \beta} \right) - \left( \frac{8 \cdot J \cdot  \mathrm{sinh}(8J \beta ) }{3+\mathrm{cosh}(8J\beta)} \right)^2 \right)\\
&=\frac{1}{k_b T^2} \left( \frac{64\cdot J\cdot \mathrm{cosh}(8 J \beta )}{3+\mathrm{cosh}(8J\beta)}  - \left( \frac{8 \cdot J \cdot \mathrm{sinh}(8J \beta ) }{3+\mathrm{cosh}(8J\beta)} \right)^2 \right)\\
&= \frac{1}{k_b T^2} \left( \frac{64 \cdot J +3\cdot J \cdot 64 \mathrm{cosh}(8J \beta)}{\left(3+\mathrm{cosh}(8J\beta)\right)^2} \right)\\
&= \frac{64}{k_b T^2} \left( \frac{ J +3 J \cdot \mathrm{cosh}(8J \beta)}{\left(3+\mathrm{cosh}(8J\beta)\right)^2} \right)\\
\end{align}
At last, we wan to have a look at the magnetic susceptibility. This quantity is a magnetic property of the material. The magnetic susceptibility describes the response of the material to an applied magnetic field. 
\begin{align}
\chi &= \frac{1}{k_b T} \cdot \left( \frac{1}{Z} \sum_{i=1}^{M} M_i^2 e^{- \beta E_i } - \left( \frac{1}{Z} \sum_{i=1}^{M} M_i e^{- \beta E_i }  \right)^2 \right)\\
&= \frac{1}{k_b T} \cdot \left( \frac{1}{Z} \cdot \left( 4^2 \cdot 1 \cdot e^{-8J\beta}+ 2^2 \cdot 4+(-2)^2 \cdot 4 + (-4)^2 \cdot 1 \cdot e^{-8J \beta } \right) - \left( 0  \right)^2 \right)\\
&= \frac{1}{k_b T} \cdot \frac{32 e^{-8J\beta}+32}{ 12+ 4 \cdot \mathrm{cosh} \left( 8J \beta \right)}\\
&= \frac{1}{k_b T} \cdot \frac{8 e^{-8J\beta}+8}{ 3+ \cdot \mathrm{cosh} \left( 8J \beta \right)}\\
\end{align}

\subsection{infinite size effect}
%Lukas will do this, have to talk with computational gys first
\subsection{everything related to parts d and later}

This part is not structured yet
%Lukas will do this
\section{Execution}

\section{Comparison and discussion of results}

\section{source code}

\end{document}
